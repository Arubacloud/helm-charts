{{ template "chart.header" . }}

{{ template "chart.description" . }}

## TL;DR

```console
$ helm repo add aruba https://github.com/Arubacloud/helm-charts

$ helm install my-release autoscaler/cluster-autoscaler \
    --set 'arubaClientID'=<ClientID>
    --set 'arubaClientSecret'=<ClientSecret>
    --set 'arubaProjectID'=<ProjectID>
    --set 'arubaRegion'=<ClientID>
    --set 'image.tag'=<k8s-version>
```

## Introduction

This chart bootstraps a cluster-autoscaler deployment on a [Kubernetes](http://kubernetes.io) cluster using the [Helm](https://helm.sh) package manager.
This chart has been modified starting from official CA Helm Chart in the https://github.com/kubernetes/autoscaler/cluster-autoscaler/charts directory and customized to work in Aruba Cloud environment.

## Prerequisites

- Helm 3+
- Kubernetes 1.30+

## Installing the Chart

**By default, no deployment is created and nothing will autoscale**.

You must provide some minimal configuration to install aruba-cluster-autoscaler.

### Aruba

The following parameters are required:

- `cloudProvider=aruba`
- `arubaClientID: "your-client-id"`
- `arubaClientSecret: "your-client-secret"`
- `arubaProjectID: "your-aruba-project-id"`
- `arubaClusterID: "your-aruba-managed-k8s-id"`
- `arubaRegion: "the-region-where-your-aruba-managed-k8s-is-deployed"`

## Uninstalling the Chart

To uninstall `my-release`:

```console
$ helm uninstall my-release
```

The command removes all the Kubernetes components associated with the chart and deletes the release.

> **Tip**: List all releases using `helm list` or start clean with `helm uninstall my-release`

## Additional Configuration

### Custom arguments

You can use the `customArgs` value to give any argument to cluster autoscaler command.

Typical use case is to give an environment variable as an argument which will be interpolated at execution time.

This is helpful when you need to inject values from configmap or secret.

## Troubleshooting

The chart will succeed even if the container arguments are incorrect. A few minutes after starting `kubectl logs -l "app=aruba-cluster-autoscaler" --tail=50` should loop through something like

```
polling_autoscaler.go:111] Poll finished
static_autoscaler.go:97] Starting main loop
utils.go:435] No pod using affinity / antiaffinity found in cluster, disabling affinity predicate for this loop
static_autoscaler.go:230] Filtering out schedulables
```

If not, find a pod that the deployment created and `describe` it, paying close attention to the arguments under `Command`. e.g.:

```
Containers:
  cluster-autoscaler:
    Command:
      - ./cluster-autoscaler
      - --cloud-provider=aruba
      - --logtostderr=true
      - --stderrthreshold=info
      - --v=4
```

### PodSecurityPolicy

Though enough for the majority of installations, the default PodSecurityPolicy _could_ be too restrictive depending on the specifics of your release. Please make sure to check that the template fits with any customizations made or disable it by setting `rbac.pspEnabled` to `false`.

### VerticalPodAutoscaler

The present chert can install a [`VerticalPodAutoscaler`](https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md) object from Chart version `1.0.0`
onwards for the Cluster Autoscaler Deployment to scale the CA as appropriate, but for that, we
need to install the VPA to the cluster separately. A VPA can help minimize wasted resources
when usage spikes periodically or remediate containers that are being OOMKilled.

The following example snippet can be used to install VPA that allows scaling down from the default recommendations of the deployment template:

```yaml
vpa:
  enabled: true
  containerPolicy:
    minAllowed:
      cpu: 20m
      memory: 50Mi
```

{{ template "chart.valuesSection" . }}
